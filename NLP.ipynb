{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DuongVinh2609/NLP/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hScJ9amyg_OI",
        "outputId": "8777be1f-de26-4828-b981-97d095d13ac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIVW8Uq9AgAR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import Perceptron, PassiveAggressiveClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# read data\n",
        "X_train = pd.read_csv('drive/MyDrive/UIT-VSFC/UIT-VSFC/train/sents.txt', sep='.', header=None, index_col=None)\n",
        "y1_train = pd.read_csv('drive/MyDrive/UIT-VSFC/UIT-VSFC/train/sentiments.txt', sep='.', header=None, index_col=None)\n",
        "y2_train = pd.read_csv('drive/MyDrive/UIT-VSFC/UIT-VSFC/train/topics.txt', sep='.', header=None, index_col=None)\n",
        "\n",
        "X_dev = pd.read_csv('drive/MyDrive/UIT-VSFC/UIT-VSFC/dev/sents.txt', sep='.', header=None, index_col=None)\n",
        "y1_dev = pd.read_csv('drive/MyDrive/UIT-VSFC/UIT-VSFC/dev/sentiments.txt', sep='.', header=None, index_col=None)\n",
        "y2_dev = pd.read_csv('drive/MyDrive/UIT-VSFC/UIT-VSFC/dev/topics.txt',  sep='.', header=None, index_col=None)\n",
        "\n",
        "X_test = pd.read_csv('drive/MyDrive/UIT-VSFC/UIT-VSFC/test/sents.txt',  sep='.', header=None, index_col=None)\n",
        "y1_test = pd.read_csv('drive/MyDrive/UIT-VSFC/UIT-VSFC/test/sentiments.txt',  sep='.', header=None, index_col=None)\n",
        "y2_test = pd.read_csv('drive/MyDrive/UIT-VSFC/UIT-VSFC/test/topics.txt',  sep='.', header=None, index_col=None)\n",
        "\n",
        "y1_train = y1_train.values.flatten()\n",
        "y1_dev = y1_dev.values.flatten()\n",
        "y1_test = y1_test.values.flatten()\n",
        "\n",
        "y2_train = y2_train.values.flatten()\n",
        "y2_dev = y2_dev.values.flatten()\n",
        "y2_test = y2_test.values.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koNiPkO2bmz-"
      },
      "outputs": [],
      "source": [
        "# pre processing data using tf-idf\n",
        "pipe = Pipeline([('count', TfidfVectorizer(ngram_range=(1, 4))),     # using 1-gram, 2-gram, 3-gram, and 4-gram\n",
        "                 ('tf_idf', TfidfTransformer(sublinear_tf=True))])   # normalized Tf-idf count matrix (using log for computation)\n",
        "\n",
        "X_train_encoded = pipe.fit_transform(X_train[0]).toarray()\n",
        "X_test_encoded = pipe.transform(X_test[0]).toarray()\n",
        "X_dev_encoded = pipe.transform(X_dev[0]).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whLut8CDbpF5"
      },
      "outputs": [],
      "source": [
        "# CREATE MACHINE LEARNING MODEL\n",
        "\n",
        "# (Modified) Perceptron\n",
        "model = PassiveAggressiveClassifier(C=1,  # maximum step size\n",
        "                                    max_iter=1000,\n",
        "                                    loss=\"hinge\",\n",
        "                                    class_weight=\"balanced\", # balanced the weight inversely proportional to class frequencies\n",
        "                                    average=True,\n",
        "                                    early_stopping=False,\n",
        "                                    warm_start=False,\n",
        "                                    verbose=True,\n",
        "                                    n_jobs=-1     # faster computation\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qloMiHjQbvPc",
        "outputId": "9b37c1c2-4e5d-4e5f-8d36-5e66bd2a45ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "-- Epoch 1\n",
            "Norm: 133.86, NNZs: 68349, Bias: 5.600312, T: 11426, Avg. loss: 0.725935\n",
            "Total training time: 12.19 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 50.63, NNZs: 113113, Bias: -1.212269, T: 11426, Avg. loss: 0.390719\n",
            "Total training time: 13.16 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 171.23, NNZs: 86797, Bias: 0.236166, T: 22852, Avg. loss: 0.382403\n",
            "Total training time: 22.29 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 65.06, NNZs: 129525, Bias: -0.584494, T: 22852, Avg. loss: 0.210270\n",
            "Total training time: 23.68 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 193.08, NNZs: 93398, Bias: -0.640071, T: 34278, Avg. loss: 0.238052\n",
            "Total training time: 32.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 74.96, NNZs: 136980, Bias: -0.689522, T: 34278, Avg. loss: 0.141185\n",
            "Total training time: 34.08 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 208.65, NNZs: 98143, Bias: -0.204271, T: 45704, Avg. loss: 0.164157\n",
            "Total training time: 41.22 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 82.47, NNZs: 140824, Bias: -0.823403, T: 45704, Avg. loss: 0.104021\n",
            "Total training time: 44.85 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 220.89, NNZs: 100236, Bias: -1.330501, T: 57130, Avg. loss: 0.122553\n",
            "Total training time: 50.72 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 87.92, NNZs: 143228, Bias: -0.952723, T: 57130, Avg. loss: 0.076091\n",
            "Total training time: 53.52 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 232.96, NNZs: 102417, Bias: -4.057517, T: 68556, Avg. loss: 0.118415\n",
            "Total training time: 60.40 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 92.23, NNZs: 144551, Bias: -0.882710, T: 68556, Avg. loss: 0.061271\n",
            "Total training time: 63.54 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 241.11, NNZs: 103966, Bias: -1.931436, T: 79982, Avg. loss: 0.091282\n",
            "Total training time: 70.05 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 95.69, NNZs: 145709, Bias: -1.729026, T: 79982, Avg. loss: 0.050617\n",
            "Total training time: 73.49 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 248.86, NNZs: 105115, Bias: -1.203175, T: 91408, Avg. loss: 0.074740\n",
            "Total training time: 78.15 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 98.60, NNZs: 146287, Bias: -1.551754, T: 91408, Avg. loss: 0.041811\n",
            "Total training time: 83.49 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 254.82, NNZs: 105712, Bias: -2.628737, T: 102834, Avg. loss: 0.058849\n",
            "Total training time: 88.22 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 101.12, NNZs: 147018, Bias: -0.977120, T: 102834, Avg. loss: 0.036894\n",
            "Total training time: 92.39 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 260.35, NNZs: 106309, Bias: -2.313763, T: 114260, Avg. loss: 0.059389\n",
            "Total training time: 97.69 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 103.15, NNZs: 147559, Bias: -1.146939, T: 114260, Avg. loss: 0.030427\n",
            "Total training time: 102.33 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 265.58, NNZs: 107181, Bias: -0.632810, T: 125686, Avg. loss: 0.052143\n",
            "Total training time: 105.79 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 105.02, NNZs: 148056, Bias: -0.997638, T: 125686, Avg. loss: 0.027918\n",
            "Total training time: 112.18 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 270.27, NNZs: 107618, Bias: 2.015652, T: 137112, Avg. loss: 0.048483\n",
            "Total training time: 115.33 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 106.62, NNZs: 148354, Bias: -1.258770, T: 137112, Avg. loss: 0.024512\n",
            "Total training time: 121.49 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 274.05, NNZs: 108292, Bias: -1.948473, T: 148538, Avg. loss: 0.040100\n",
            "Total training time: 124.85 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 108.11, NNZs: 148499, Bias: -1.094969, T: 148538, Avg. loss: 0.021978\n",
            "Total training time: 130.34 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 277.05, NNZs: 108530, Bias: -2.965716, T: 159964, Avg. loss: 0.037662\n",
            "Total training time: 133.28 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 109.49, NNZs: 148730, Bias: -1.254206, T: 159964, Avg. loss: 0.020646\n",
            "Total training time: 140.10 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 280.52, NNZs: 109023, Bias: 0.764615, T: 171390, Avg. loss: 0.033650\n",
            "Total training time: 142.41 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 110.60, NNZs: 148850, Bias: -1.406355, T: 171390, Avg. loss: 0.017089\n",
            "Total training time: 149.76 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 283.88, NNZs: 109176, Bias: -2.402774, T: 182816, Avg. loss: 0.032467\n",
            "Total training time: 152.02 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 111.85, NNZs: 148934, Bias: -1.200682, T: 182816, Avg. loss: 0.018490\n",
            "Total training time: 158.03 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 286.62, NNZs: 109585, Bias: -3.546146, T: 194242, Avg. loss: 0.030860\n",
            "Total training time: 161.33 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 112.90, NNZs: 149036, Bias: -0.886414, T: 194242, Avg. loss: 0.015885\n",
            "Total training time: 167.69 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 288.66, NNZs: 109644, Bias: -3.706412, T: 205668, Avg. loss: 0.023255\n",
            "Total training time: 169.56 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 113.86, NNZs: 149284, Bias: -1.209193, T: 205668, Avg. loss: 0.014621\n",
            "Total training time: 177.49 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 290.75, NNZs: 109767, Bias: -3.801796, T: 217094, Avg. loss: 0.021111\n",
            "Total training time: 179.00 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 114.75, NNZs: 149425, Bias: -1.348893, T: 217094, Avg. loss: 0.013491\n",
            "Total training time: 186.54 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 292.79, NNZs: 110052, Bias: -3.660507, T: 228520, Avg. loss: 0.022771\n",
            "Total training time: 188.56 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 115.47, NNZs: 149542, Bias: -1.448635, T: 228520, Avg. loss: 0.011259\n",
            "Total training time: 195.47 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 294.40, NNZs: 110199, Bias: -4.063491, T: 239946, Avg. loss: 0.017333\n",
            "Total training time: 196.61 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 116.25, NNZs: 149591, Bias: -1.418477, T: 239946, Avg. loss: 0.011522\n",
            "Total training time: 205.19 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 295.45, NNZs: 110247, Bias: -3.680621, T: 251372, Avg. loss: 0.013340\n",
            "Total training time: 206.13 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 116.98, NNZs: 149599, Bias: -1.441542, T: 251372, Avg. loss: 0.011180\n",
            "Total training time: 214.75 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 297.31, NNZs: 110311, Bias: -3.940321, T: 262798, Avg. loss: 0.022673\n",
            "Total training time: 215.71 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 117.68, NNZs: 149669, Bias: -1.338361, T: 262798, Avg. loss: 0.010340\n",
            "Total training time: 222.94 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 299.59, NNZs: 110515, Bias: -2.248774, T: 274224, Avg. loss: 0.022284\n",
            "Total training time: 223.75 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 118.29, NNZs: 149700, Bias: -1.321620, T: 274224, Avg. loss: 0.009382\n",
            "Total training time: 232.63 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 301.90, NNZs: 110700, Bias: -0.556475, T: 285650, Avg. loss: 0.021904\n",
            "Total training time: 233.25 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 118.89, NNZs: 149788, Bias: -1.078580, T: 285650, Avg. loss: 0.008798\n",
            "Total training time: 242.24 seconds.\n",
            "Convergence after 25 epochs took 242.25 seconds\n",
            "-- Epoch 1\n",
            "Norm: 303.33, NNZs: 110827, Bias: -3.173521, T: 297076, Avg. loss: 0.019863\n",
            "Total training time: 242.80 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 305.43, NNZs: 111048, Bias: -4.027302, T: 308502, Avg. loss: 0.022220\n",
            "Total training time: 251.31 seconds.\n",
            "Convergence after 27 epochs took 251.31 seconds\n",
            "Norm: 44.46, NNZs: 90058, Bias: -0.466955, T: 11426, Avg. loss: 0.338506\n",
            "Total training time: 10.16 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 58.00, NNZs: 107344, Bias: -0.700781, T: 22852, Avg. loss: 0.196795\n",
            "Total training time: 16.60 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 67.52, NNZs: 115477, Bias: 0.347167, T: 34278, Avg. loss: 0.141149\n",
            "Total training time: 23.52 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 74.83, NNZs: 120943, Bias: -0.435167, T: 45704, Avg. loss: 0.108363\n",
            "Total training time: 29.69 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 80.43, NNZs: 124144, Bias: -0.478170, T: 57130, Avg. loss: 0.084342\n",
            "Total training time: 37.22 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 84.86, NNZs: 126242, Bias: -0.595024, T: 68556, Avg. loss: 0.068774\n",
            "Total training time: 45.50 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 88.56, NNZs: 128157, Bias: -0.595691, T: 79982, Avg. loss: 0.058185\n",
            "Total training time: 52.36 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 91.59, NNZs: 129215, Bias: 0.178512, T: 91408, Avg. loss: 0.048757\n",
            "Total training time: 58.32 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 94.21, NNZs: 129947, Bias: -0.039829, T: 102834, Avg. loss: 0.042777\n",
            "Total training time: 65.16 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 96.53, NNZs: 130547, Bias: 0.021880, T: 114260, Avg. loss: 0.038710\n",
            "Total training time: 71.11 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 98.56, NNZs: 131032, Bias: -0.485071, T: 125686, Avg. loss: 0.034229\n",
            "Total training time: 78.98 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 100.36, NNZs: 131549, Bias: -0.135220, T: 137112, Avg. loss: 0.030777\n",
            "Total training time: 84.90 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 101.90, NNZs: 132000, Bias: -0.235967, T: 148538, Avg. loss: 0.027963\n",
            "Total training time: 91.68 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 103.24, NNZs: 132607, Bias: 0.228040, T: 159964, Avg. loss: 0.025556\n",
            "Total training time: 97.56 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 104.55, NNZs: 132850, Bias: 0.215156, T: 171390, Avg. loss: 0.024378\n",
            "Total training time: 104.30 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 105.68, NNZs: 133002, Bias: 0.369772, T: 182816, Avg. loss: 0.022493\n",
            "Total training time: 110.16 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 106.72, NNZs: 133082, Bias: 0.154593, T: 194242, Avg. loss: 0.021176\n",
            "Total training time: 116.87 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 107.88, NNZs: 133516, Bias: 0.117399, T: 205668, Avg. loss: 0.021566\n",
            "Total training time: 122.72 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 108.78, NNZs: 133677, Bias: -0.031902, T: 217094, Avg. loss: 0.019127\n",
            "Total training time: 129.41 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 109.64, NNZs: 133918, Bias: 0.179612, T: 228520, Avg. loss: 0.017889\n",
            "Total training time: 135.21 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 110.45, NNZs: 134082, Bias: 0.333061, T: 239946, Avg. loss: 0.017520\n",
            "Total training time: 141.90 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 111.31, NNZs: 134251, Bias: 0.042467, T: 251372, Avg. loss: 0.017419\n",
            "Total training time: 147.69 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 112.02, NNZs: 134367, Bias: 0.242700, T: 262798, Avg. loss: 0.016077\n",
            "Total training time: 154.21 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 112.76, NNZs: 134565, Bias: 0.089918, T: 274224, Avg. loss: 0.016102\n",
            "Total training time: 160.18 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 113.41, NNZs: 134609, Bias: 0.508507, T: 285650, Avg. loss: 0.015140\n",
            "Total training time: 166.50 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 114.12, NNZs: 134797, Bias: 0.257330, T: 297076, Avg. loss: 0.015475\n",
            "Total training time: 172.65 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 114.76, NNZs: 134830, Bias: 0.111642, T: 308502, Avg. loss: 0.014159\n",
            "Total training time: 178.77 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 115.44, NNZs: 134873, Bias: 0.162079, T: 319928, Avg. loss: 0.014555\n",
            "Total training time: 185.10 seconds.\n",
            "Convergence after 28 epochs took 185.10 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  7.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiments Performance:\n",
            "           precision          recall           f1 score\n",
            "positive: [89.98716302952504, 88.17610062893083, 89.07242693773824]\n",
            "negative: [85.88628762541805, 91.12845990063875, 88.42975206611571]\n",
            "neutral:  [37.16814159292036, 25.149700598802394, 30.0]\n",
            "average:  [85.37601014756049, 86.16550852811118, 85.67046098931169]\n"
          ]
        }
      ],
      "source": [
        "# sentiment analysis model using (Modified) Perceptron\n",
        "sentiment_model = model\n",
        "sentiment_model.fit(X_train_encoded, y1_train)\n",
        "y1_pred = sentiment_model.predict(X_test_encoded)\n",
        "\n",
        "\n",
        "\n",
        "# sentiments performance\n",
        "sentiment_precision_score = precision_score(y1_test, y1_pred, average=None)*100\n",
        "sentiment_weighted_average_precision = precision_score(y1_test, y1_pred, average=\"weighted\")*100\n",
        "\n",
        "sentiment_recall_score = recall_score(y1_test, y1_pred, average=None)*100\n",
        "sentiment_weighted_average_recall = recall_score(y1_test, y1_pred, average=\"weighted\")*100\n",
        "\n",
        "sentiment_f1_score = f1_score(y1_test, y1_pred, average=None)*100\n",
        "sentiment_weighted_average_f1_score = f1_score(y1_test, y1_pred, average=\"weighted\")*100\n",
        "\n",
        "print(\"Sentiments Performance:\")\n",
        "print(\"           precision          recall           f1 score\")\n",
        "print(\"positive:\", [sentiment_precision_score[2], sentiment_recall_score[2], sentiment_f1_score[2]])\n",
        "print(\"negative:\", [sentiment_precision_score[0], sentiment_recall_score[0], sentiment_f1_score[0]])\n",
        "print(\"neutral: \", [sentiment_precision_score[1], sentiment_recall_score[1], sentiment_f1_score[1]])\n",
        "# weighted average\n",
        "print(\"average: \", [sentiment_weighted_average_precision, sentiment_weighted_average_recall, sentiment_weighted_average_f1_score])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n48XEnc1byED",
        "outputId": "1ac7b1f8-ac4a-4f44-a977-2a6740d1cb75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "-- Epoch 1\n",
            "Norm: 57.92, NNZs: 103395, Bias: -2.303037, T: 11426, Avg. loss: 0.404330\n",
            "Total training time: 10.97 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 37.06, NNZs: 131231, Bias: -1.134262, T: 11426, Avg. loss: 0.475677\n",
            "Total training time: 11.51 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 77.65, NNZs: 123744, Bias: -1.678129, T: 22852, Avg. loss: 0.237173\n",
            "Total training time: 21.36 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 48.98, NNZs: 145573, Bias: -0.409772, T: 22852, Avg. loss: 0.310476\n",
            "Total training time: 22.45 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 91.72, NNZs: 132250, Bias: -2.036893, T: 34278, Avg. loss: 0.158511\n",
            "Total training time: 32.52 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 59.33, NNZs: 152746, Bias: -0.786634, T: 34278, Avg. loss: 0.243575\n",
            "Total training time: 34.70 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 101.67, NNZs: 136247, Bias: -1.655470, T: 45704, Avg. loss: 0.110372\n",
            "Total training time: 41.72 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 67.30, NNZs: 156272, Bias: -0.571008, T: 45704, Avg. loss: 0.192804\n",
            "Total training time: 44.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 109.33, NNZs: 139187, Bias: -1.313605, T: 57130, Avg. loss: 0.084511\n",
            "Total training time: 51.85 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 73.77, NNZs: 158312, Bias: -1.009325, T: 57130, Avg. loss: 0.156976\n",
            "Total training time: 54.45 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 115.14, NNZs: 140509, Bias: -1.581028, T: 68556, Avg. loss: 0.066470\n",
            "Total training time: 61.70 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 78.92, NNZs: 159770, Bias: -0.000051, T: 68556, Avg. loss: 0.130447\n",
            "Total training time: 64.98 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 119.59, NNZs: 141621, Bias: -1.476116, T: 79982, Avg. loss: 0.050838\n",
            "Total training time: 70.18 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 83.52, NNZs: 160492, Bias: -0.204125, T: 79982, Avg. loss: 0.113217\n",
            "Total training time: 75.45 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 123.37, NNZs: 142489, Bias: -2.017027, T: 91408, Avg. loss: 0.045508\n",
            "Total training time: 79.87 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 87.42, NNZs: 161186, Bias: -0.676940, T: 91408, Avg. loss: 0.098642\n",
            "Total training time: 85.17 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 126.52, NNZs: 142967, Bias: -1.507150, T: 102834, Avg. loss: 0.037011\n",
            "Total training time: 89.65 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 90.75, NNZs: 161865, Bias: -0.596411, T: 102834, Avg. loss: 0.086544\n",
            "Total training time: 94.67 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 129.21, NNZs: 143240, Bias: -2.143413, T: 114260, Avg. loss: 0.033997\n",
            "Total training time: 99.30 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 93.72, NNZs: 162179, Bias: -0.139690, T: 114260, Avg. loss: 0.077857\n",
            "Total training time: 104.88 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 131.40, NNZs: 143764, Bias: -1.994823, T: 125686, Avg. loss: 0.027989\n",
            "Total training time: 107.73 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 96.27, NNZs: 162570, Bias: 0.045537, T: 125686, Avg. loss: 0.069079\n",
            "Total training time: 115.02 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 133.41, NNZs: 144171, Bias: -1.694816, T: 137112, Avg. loss: 0.025755\n",
            "Total training time: 117.47 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 98.56, NNZs: 162726, Bias: -0.267967, T: 137112, Avg. loss: 0.064276\n",
            "Total training time: 124.49 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 135.26, NNZs: 144479, Bias: -1.716429, T: 148538, Avg. loss: 0.024434\n",
            "Total training time: 127.16 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 100.62, NNZs: 162851, Bias: -0.157683, T: 148538, Avg. loss: 0.058015\n",
            "Total training time: 133.86 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 136.95, NNZs: 144733, Bias: -1.990972, T: 159964, Avg. loss: 0.021711\n",
            "Total training time: 135.39 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 102.46, NNZs: 163087, Bias: -0.057098, T: 159964, Avg. loss: 0.053389\n",
            "Total training time: 144.00 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 138.31, NNZs: 144919, Bias: -1.769698, T: 171390, Avg. loss: 0.018601\n",
            "Total training time: 145.03 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 104.17, NNZs: 163189, Bias: -0.261615, T: 171390, Avg. loss: 0.049518\n",
            "Total training time: 155.19 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 139.61, NNZs: 145010, Bias: -1.741137, T: 182816, Avg. loss: 0.017817\n",
            "Total training time: 155.99 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 105.79, NNZs: 163242, Bias: 0.068851, T: 182816, Avg. loss: 0.047113\n",
            "Total training time: 164.84 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 141.00, NNZs: 145192, Bias: -1.902229, T: 194242, Avg. loss: 0.018309\n",
            "Total training time: 165.55 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 142.15, NNZs: 145310, Bias: -2.178981, T: 205668, Avg. loss: 0.016038\n",
            "Total training time: 173.79 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 107.27, NNZs: 163326, Bias: -0.802244, T: 194242, Avg. loss: 0.043801\n",
            "Total training time: 173.86 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 143.26, NNZs: 145344, Bias: -2.324343, T: 217094, Avg. loss: 0.015869\n",
            "Total training time: 183.48 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 108.72, NNZs: 163546, Bias: -0.156847, T: 205668, Avg. loss: 0.042677\n",
            "Total training time: 183.86 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 144.22, NNZs: 145521, Bias: -2.008229, T: 228520, Avg. loss: 0.013622\n",
            "Total training time: 193.44 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 110.00, NNZs: 163610, Bias: -0.208861, T: 217094, Avg. loss: 0.039168\n",
            "Total training time: 194.02 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 145.25, NNZs: 145706, Bias: -1.686340, T: 239946, Avg. loss: 0.014797\n",
            "Total training time: 201.59 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 111.21, NNZs: 163675, Bias: -0.118176, T: 228520, Avg. loss: 0.036892\n",
            "Total training time: 202.51 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 146.24, NNZs: 145865, Bias: -1.922994, T: 251372, Avg. loss: 0.013780\n",
            "Total training time: 211.23 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 112.40, NNZs: 163693, Bias: -0.078596, T: 239946, Avg. loss: 0.036688\n",
            "Total training time: 212.35 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 147.06, NNZs: 145948, Bias: -2.115748, T: 262798, Avg. loss: 0.012719\n",
            "Total training time: 220.81 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 113.54, NNZs: 163751, Bias: -0.113207, T: 251372, Avg. loss: 0.034172\n",
            "Total training time: 222.30 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 147.78, NNZs: 146083, Bias: -2.056348, T: 274224, Avg. loss: 0.010830\n",
            "Total training time: 228.98 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 114.61, NNZs: 163856, Bias: -0.063499, T: 262798, Avg. loss: 0.032698\n",
            "Total training time: 232.25 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 148.53, NNZs: 146153, Bias: -2.222822, T: 285650, Avg. loss: 0.011501\n",
            "Total training time: 238.45 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 115.66, NNZs: 163923, Bias: 0.093250, T: 274224, Avg. loss: 0.032030\n",
            "Total training time: 240.64 seconds.\n",
            "-- Epoch 25\n",
            "Norm: 149.22, NNZs: 146198, Bias: -1.880824, T: 297076, Avg. loss: 0.010290\n",
            "Total training time: 248.04 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 116.61, NNZs: 163989, Bias: -0.195962, T: 285650, Avg. loss: 0.029660\n",
            "Total training time: 250.56 seconds.\n",
            "-- Epoch 26\n",
            "Norm: 149.96, NNZs: 146267, Bias: -1.927374, T: 308502, Avg. loss: 0.011061\n",
            "Total training time: 257.35 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 117.58, NNZs: 163998, Bias: -0.240338, T: 297076, Avg. loss: 0.030031\n",
            "Total training time: 260.63 seconds.\n",
            "-- Epoch 27\n",
            "Norm: 150.64, NNZs: 146344, Bias: -1.791078, T: 319928, Avg. loss: 0.010103\n",
            "Total training time: 266.05 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 118.47, NNZs: 164010, Bias: 0.057806, T: 308502, Avg. loss: 0.027767\n",
            "Total training time: 269.94 seconds.\n",
            "-- Epoch 28\n",
            "Norm: 151.42, NNZs: 146380, Bias: -2.206522, T: 331354, Avg. loss: 0.010946\n",
            "Total training time: 275.71 seconds.\n",
            "Convergence after 29 epochs took 275.71 seconds\n",
            "-- Epoch 1\n",
            "Norm: 119.29, NNZs: 164126, Bias: -0.178388, T: 319928, Avg. loss: 0.026150\n",
            "Total training time: 278.96 seconds.\n",
            "-- Epoch 29\n",
            "Norm: 77.89, NNZs: 34321, Bias: -2.434360, T: 11426, Avg. loss: 0.164661\n",
            "Total training time: 10.44 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 120.12, NNZs: 164143, Bias: -0.062221, T: 331354, Avg. loss: 0.026447\n",
            "Total training time: 289.33 seconds.\n",
            "-- Epoch 30\n",
            "Norm: 90.31, NNZs: 40353, Bias: -0.606904, T: 22852, Avg. loss: 0.043648\n",
            "Total training time: 18.57 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 120.92, NNZs: 164176, Bias: -0.040818, T: 342780, Avg. loss: 0.025390\n",
            "Total training time: 299.17 seconds.\n",
            "-- Epoch 31\n",
            "Norm: 93.80, NNZs: 42455, Bias: -3.454575, T: 34278, Avg. loss: 0.017091\n",
            "Total training time: 28.23 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 121.65, NNZs: 164185, Bias: 0.064378, T: 354206, Avg. loss: 0.023998\n",
            "Total training time: 310.61 seconds.\n",
            "-- Epoch 32\n",
            "Norm: 95.73, NNZs: 43409, Bias: -4.174687, T: 45704, Avg. loss: 0.011683\n",
            "Total training time: 39.00 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 122.41, NNZs: 164228, Bias: -0.218278, T: 365632, Avg. loss: 0.024042\n",
            "Total training time: 319.07 seconds.\n",
            "-- Epoch 33\n",
            "Norm: 97.30, NNZs: 43976, Bias: -3.708550, T: 57130, Avg. loss: 0.009413\n",
            "Total training time: 50.44 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 123.12, NNZs: 164245, Bias: -0.241310, T: 377058, Avg. loss: 0.023198\n",
            "Total training time: 330.86 seconds.\n",
            "-- Epoch 34\n",
            "Norm: 98.88, NNZs: 44424, Bias: -2.877798, T: 68556, Avg. loss: 0.007686\n",
            "Total training time: 58.71 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 123.81, NNZs: 164282, Bias: -0.054677, T: 388484, Avg. loss: 0.022482\n",
            "Total training time: 342.58 seconds.\n",
            "-- Epoch 35\n",
            "Norm: 100.61, NNZs: 44845, Bias: -2.316708, T: 79982, Avg. loss: 0.006646\n",
            "Total training time: 69.97 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 124.47, NNZs: 164325, Bias: 0.018865, T: 399910, Avg. loss: 0.021583\n",
            "Total training time: 353.92 seconds.\n",
            "-- Epoch 36\n",
            "Norm: 101.03, NNZs: 45019, Bias: -0.616809, T: 91408, Avg. loss: 0.003488\n",
            "Total training time: 81.10 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 125.07, NNZs: 164325, Bias: 0.025209, T: 411336, Avg. loss: 0.020110\n",
            "Total training time: 363.82 seconds.\n",
            "-- Epoch 37\n",
            "Norm: 101.95, NNZs: 45398, Bias: -1.962812, T: 102834, Avg. loss: 0.004875\n",
            "Total training time: 90.52 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 125.64, NNZs: 164359, Bias: -0.222095, T: 422762, Avg. loss: 0.019709\n",
            "Total training time: 372.19 seconds.\n",
            "-- Epoch 38\n",
            "Norm: 102.37, NNZs: 45759, Bias: -3.689414, T: 114260, Avg. loss: 0.002840\n",
            "Total training time: 98.73 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 126.23, NNZs: 164383, Bias: 0.045921, T: 434188, Avg. loss: 0.019753\n",
            "Total training time: 382.05 seconds.\n",
            "-- Epoch 39\n",
            "Norm: 103.59, NNZs: 46054, Bias: -3.734990, T: 125686, Avg. loss: 0.003616\n",
            "Total training time: 108.06 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 126.82, NNZs: 164399, Bias: 0.237124, T: 445614, Avg. loss: 0.019883\n",
            "Total training time: 391.80 seconds.\n",
            "-- Epoch 40\n",
            "Norm: 104.56, NNZs: 46352, Bias: -2.094911, T: 137112, Avg. loss: 0.003005\n",
            "Total training time: 117.53 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 127.36, NNZs: 164431, Bias: -0.245222, T: 457040, Avg. loss: 0.018251\n",
            "Total training time: 400.17 seconds.\n",
            "-- Epoch 41\n",
            "Norm: 104.97, NNZs: 46453, Bias: -2.864406, T: 148538, Avg. loss: 0.000975\n",
            "Total training time: 126.45 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 127.88, NNZs: 164544, Bias: 0.104689, T: 468466, Avg. loss: 0.018084\n",
            "Total training time: 410.00 seconds.\n",
            "-- Epoch 42\n",
            "Norm: 105.58, NNZs: 46676, Bias: -2.787227, T: 159964, Avg. loss: 0.001727\n",
            "Total training time: 134.90 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 128.44, NNZs: 164562, Bias: 0.095171, T: 479892, Avg. loss: 0.018551\n",
            "Total training time: 419.75 seconds.\n",
            "-- Epoch 43\n",
            "Norm: 105.74, NNZs: 46726, Bias: -3.504589, T: 171390, Avg. loss: 0.000583\n",
            "Total training time: 144.33 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 128.97, NNZs: 164605, Bias: 0.071237, T: 491318, Avg. loss: 0.017907\n",
            "Total training time: 429.46 seconds.\n",
            "-- Epoch 44\n",
            "Norm: 106.25, NNZs: 46880, Bias: -2.173780, T: 182816, Avg. loss: 0.000986\n",
            "Total training time: 153.85 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 106.92, NNZs: 47131, Bias: -3.266756, T: 194242, Avg. loss: 0.001803\n",
            "Total training time: 161.86 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 129.47, NNZs: 164605, Bias: -0.005677, T: 502744, Avg. loss: 0.016967\n",
            "Total training time: 437.78 seconds.\n",
            "-- Epoch 45\n",
            "Norm: 106.96, NNZs: 47131, Bias: -3.275934, T: 205668, Avg. loss: 0.000170\n",
            "Total training time: 171.25 seconds.\n",
            "Convergence after 18 epochs took 171.25 seconds\n",
            "-- Epoch 1\n",
            "Norm: 129.99, NNZs: 164611, Bias: 0.161190, T: 514170, Avg. loss: 0.017219\n",
            "Total training time: 447.65 seconds.\n",
            "Convergence after 45 epochs took 447.65 seconds\n",
            "Norm: 96.66, NNZs: 67146, Bias: -0.088075, T: 11426, Avg. loss: 0.433601\n",
            "Total training time: 7.85 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 121.82, NNZs: 83882, Bias: -0.527073, T: 22852, Avg. loss: 0.217447\n",
            "Total training time: 14.04 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 139.35, NNZs: 91981, Bias: 2.444092, T: 34278, Avg. loss: 0.135627\n",
            "Total training time: 20.62 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 150.86, NNZs: 96258, Bias: -1.097977, T: 45704, Avg. loss: 0.091906\n",
            "Total training time: 26.76 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 161.62, NNZs: 98542, Bias: -0.762925, T: 57130, Avg. loss: 0.081643\n",
            "Total training time: 33.19 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 168.33, NNZs: 100157, Bias: 0.190302, T: 68556, Avg. loss: 0.057317\n",
            "Total training time: 39.38 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 174.63, NNZs: 101516, Bias: -0.802419, T: 79982, Avg. loss: 0.047162\n",
            "Total training time: 45.57 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 180.18, NNZs: 102580, Bias: -0.813556, T: 91408, Avg. loss: 0.041627\n",
            "Total training time: 51.95 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 184.04, NNZs: 103370, Bias: -0.439223, T: 102834, Avg. loss: 0.033594\n",
            "Total training time: 58.02 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 188.41, NNZs: 103995, Bias: -1.879857, T: 114260, Avg. loss: 0.030683\n",
            "Total training time: 64.49 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 191.65, NNZs: 104416, Bias: -0.434825, T: 125686, Avg. loss: 0.027187\n",
            "Total training time: 70.40 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 193.75, NNZs: 104603, Bias: -2.071740, T: 137112, Avg. loss: 0.016862\n",
            "Total training time: 76.98 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 196.27, NNZs: 104964, Bias: -1.267403, T: 148538, Avg. loss: 0.019277\n",
            "Total training time: 82.83 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 198.29, NNZs: 105161, Bias: -1.321877, T: 159964, Avg. loss: 0.014830\n",
            "Total training time: 89.98 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 200.74, NNZs: 105392, Bias: -1.178328, T: 171390, Avg. loss: 0.017588\n",
            "Total training time: 95.81 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 202.65, NNZs: 105633, Bias: -0.817893, T: 182816, Avg. loss: 0.015130\n",
            "Total training time: 102.53 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 204.02, NNZs: 105795, Bias: -1.578405, T: 194242, Avg. loss: 0.010523\n",
            "Total training time: 108.28 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 205.15, NNZs: 105905, Bias: -1.475066, T: 205668, Avg. loss: 0.011591\n",
            "Total training time: 114.87 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 206.23, NNZs: 105995, Bias: -2.081145, T: 217094, Avg. loss: 0.008677\n",
            "Total training time: 120.63 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 207.54, NNZs: 106226, Bias: -0.795396, T: 228520, Avg. loss: 0.010081\n",
            "Total training time: 127.26 seconds.\n",
            "-- Epoch 21\n",
            "Norm: 208.48, NNZs: 106349, Bias: -2.400834, T: 239946, Avg. loss: 0.007755\n",
            "Total training time: 133.01 seconds.\n",
            "-- Epoch 22\n",
            "Norm: 209.70, NNZs: 106511, Bias: -1.157203, T: 251372, Avg. loss: 0.008735\n",
            "Total training time: 140.48 seconds.\n",
            "-- Epoch 23\n",
            "Norm: 210.93, NNZs: 106563, Bias: -1.329873, T: 262798, Avg. loss: 0.010113\n",
            "Total training time: 146.26 seconds.\n",
            "-- Epoch 24\n",
            "Norm: 212.42, NNZs: 106697, Bias: 0.019625, T: 274224, Avg. loss: 0.010052\n",
            "Total training time: 152.85 seconds.\n",
            "Convergence after 24 epochs took 152.85 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed: 10.0min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics Performance\n",
            "             precision          recall           f1 score\n",
            "lecturer:   [91.33893062306673, 90.26200873362446, 90.79727652097519]\n",
            "curriculum: [65.72769953051643, 73.42657342657343, 69.36416184971098]\n",
            "facility:   [90.97744360902256, 83.44827586206897, 87.05035971223022]\n",
            "others:     [40.458015267175576, 33.33333333333333, 36.55172413793103]\n",
            "average:    [84.1399080887768, 84.04927353126975, 84.02908721013021]\n"
          ]
        }
      ],
      "source": [
        "# topics analysis model using (Modified) Perceptron\n",
        "topic_model = model\n",
        "topic_model.fit(X_train_encoded, y2_train)\n",
        "y2_pred = topic_model.predict(X_test_encoded)\n",
        "\n",
        "\n",
        "# Topics performance\n",
        "topics_precision_score = precision_score(y2_test, y2_pred, average=None)*100\n",
        "topics_weighted_average_precision = precision_score(y2_test, y2_pred, average=\"weighted\")*100\n",
        "\n",
        "topics_recall_score = recall_score(y2_test, y2_pred, average=None)*100\n",
        "topics_weighted_average_recall = recall_score(y2_test, y2_pred, average=\"weighted\")*100\n",
        "\n",
        "topics_f1_score = f1_score(y2_test, y2_pred, average=None)*100\n",
        "topics_weighted_average_f1_score = f1_score(y2_test, y2_pred, average=\"weighted\")*100\n",
        "\n",
        "print(\"Topics Performance\")\n",
        "print(\"             precision          recall           f1 score\")\n",
        "print(\"lecturer:  \", [topics_precision_score[0], topics_recall_score[0], topics_f1_score[0]])\n",
        "print(\"curriculum:\", [topics_precision_score[1], topics_recall_score[1], topics_f1_score[1]])\n",
        "print(\"facility:  \", [topics_precision_score[2], topics_recall_score[2], topics_f1_score[2]])\n",
        "print(\"others:    \", [topics_precision_score[3], topics_recall_score[3], topics_f1_score[3]])\n",
        "# weighted average\n",
        "print(\"average:   \", [topics_weighted_average_precision, topics_weighted_average_recall, topics_weighted_average_f1_score])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}